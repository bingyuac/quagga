# TODO

- [ ] Matrix assertions
    - [ ] Add shape assertions into Cpu/GpuMatrix methods
    - [ ] Add contexts assertions into Cpu/GpuMatrix methods
- [ ] Add benchmarks
- [x] Implement MergeBlock
    - [x] Implement VStackBlock
        - [x] add VStackBlock
        - [x] Implement vstack in Cpu/GpuMatrix classes
        - [x] Implement vsplit in Cpu/GpuMatrix classes
        - [x] Add tests
    - [x] Implement HStackBlock
        - [x] add HStackBlock
        - [x] Implement hstack kernel
        - [x] Implement hstack in Cpu/GpuMatrix classes
        - [x] Add tests
- [ ] Cpu/GpuMatrix improvement    
    - [ ] Fix tests current tests
    - [ ] Review current usage of kernels
    - [ ] Synchronize Cpu/GpuMatrix classes
- [x] Implement EmbeddingBlock    
- [x] Implement MeanPoolingBlock
    - [x] Implement `tile` method
    - [x] Add `tile` test
    - [x] Add tests
- [ ] Implement MaxPoolingBlock
- [x] Add multi-gpu Context (http://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_multi_gpu.pdf)
- [ ] Add different types of Optimizers
    - [x] Implement SgdOptimizer
    - [ ] Implement NagOptimizer
- [ ] Add learning rate and momentum policies
    - [x] Implemented fixed learning policy
- [ ] Add reduction kernels for mean value
- [ ] Review usage of `vsplit` and `hsplit` (python code instead of c)
- [ ] Add fast dropout LSTM
- [ ] Add compiler functionality for more flexible code generation
- [ ] Add max margin cost function
- [ ] Rewrite `_verticalStack` and `_horizontalStack` using kernels instead of cudamemcopy
- [ ] Change logic into empty like with default device_id borrow it from like matrix
- [ ] use device api for dropout instead of host api
- [ ] Think about dropout and scaled layer It should not take to many memory, you should write a mechanism for this
- [ ] Add broadcasting to Matrix Operations
- [ ] Check fprop for output variables in the each block fprop function
- [ ] There are sometimes a very nasty bugs connected with using matrix when it is not calculated completely you should always keep an eye on a proper synchronization
- [ ] Check all np.allclose into test_Matrix tests for the right checking, sometimes there are typos 
- [ ] Fix blocks tests and unify block interface